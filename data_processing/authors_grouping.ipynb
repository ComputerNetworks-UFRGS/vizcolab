{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import os, glob, multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('‚öôÔ∏è Importing authors...')\n",
    "\n",
    "path = os.path.join('datasets/autores/', \"autores-*.csv\")\n",
    "data_files = glob.glob(path) \n",
    "print(*data_files, sep = \"\\n\")\n",
    "\n",
    "df = pd.concat(pd.read_csv(f, encoding='iso8859_1', delimiter=\";\") for f in data_files)\n",
    "\n",
    "# Only selects author 5% sample of the dataset\n",
    "# df = df.sample(frac=0.05, random_state=1)\n",
    "\n",
    "print(\"   {} authors in the dataset\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter fields of interest\n",
    "df = df.filter([\n",
    "  'AN_BASE',\n",
    "  'NM_AUTOR',\n",
    "  'NM_ABNT_AUTOR',\n",
    "  'TP_AUTOR',\n",
    "  'NM_TP_CATEGORIA_DOCENTE',\n",
    "  'NM_NIVEL_DISCENTE',\n",
    "  'CD_PROGRAMA_IES',\n",
    "  'NM_PROGRAMA_IES',\n",
    "  'NM_AREA_CONHECIMENTO',\n",
    "  'SG_ENTIDADE_ENSINO',\n",
    "  'ID_PESSOA_DISCENTE',\n",
    "  'ID_PESSOA_DOCENTE',\n",
    "  'ID_PESSOA_PART_EXTERNO',\n",
    "  'ID_PESSOA_POS_DOC',\n",
    "  'ID_PESSOA_EGRESSO',\n",
    "  'ID_ADD_PRODUCAO_INTELECTUAL',\n",
    "])\n",
    "\n",
    "# Unify IDs\n",
    "def unify_ids(cols):\n",
    "    return {\n",
    "      'DOCENTE': cols['ID_PESSOA_DOCENTE'],\n",
    "      'EGRESSO': cols['ID_PESSOA_EGRESSO'],\n",
    "      'P√ìS-DOC': cols['ID_PESSOA_POS_DOC'],\n",
    "      'DISCENTE': cols['ID_PESSOA_DISCENTE'],\n",
    "      'PARTICIPANTE EXTERNO': cols['ID_PESSOA_PART_EXTERNO'],\n",
    "      '-': None,\n",
    "    }[cols['TP_AUTOR']]\n",
    "\n",
    "ids = [\n",
    "  'ID_PESSOA_DISCENTE',\n",
    "  'ID_PESSOA_DOCENTE',\n",
    "  'ID_PESSOA_PART_EXTERNO',\n",
    "  'ID_PESSOA_POS_DOC',\n",
    "  'ID_PESSOA_EGRESSO',\n",
    "]\n",
    "\n",
    "print('‚öôÔ∏è Unifying author IDs...')\n",
    "df['ID'] = df[['TP_AUTOR', *ids]].apply(unify_ids, axis=1)\n",
    "df = df.drop(columns=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚öôÔ∏è Normalizing df names...')\n",
    "df['NM_AUTOR'] = df['NM_AUTOR'].apply(utils.normalize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚öôÔ∏è Creating helper columns...')\n",
    "df['FIRST_LAST_NAME'] = df['NM_AUTOR'].apply(utils.firstAndLastName)\n",
    "df['FULL_NAME'] = df['NM_AUTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_schema = {\n",
    "  'FULL_NAME': 'first',\n",
    "  'NM_AUTOR': utils.count_to_dict,\n",
    "  'NM_ABNT_AUTOR': utils.count_to_dict,\n",
    "  'FIRST_LAST_NAME': utils.count_to_dict,\n",
    "  'TP_AUTOR': utils.count_to_dict,\n",
    "  'NM_TP_CATEGORIA_DOCENTE': utils.count_to_dict,\n",
    "  'NM_NIVEL_DISCENTE': utils.count_to_dict,\n",
    "  'CD_PROGRAMA_IES': utils.count_to_dict,\n",
    "  'NM_PROGRAMA_IES': utils.count_to_dict,\n",
    "  'NM_AREA_CONHECIMENTO': utils.count_to_dict,\n",
    "  'SG_ENTIDADE_ENSINO': utils.count_to_dict,\n",
    "  'ID_ADD_PRODUCAO_INTELECTUAL': list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df by ID\n",
    "print('‚öôÔ∏è Merging authors by ID...')\n",
    "merged_authors = df.groupby(['ID'], sort=False, as_index=False).agg(merge_schema)\n",
    "print(\"   {} authors with ID after merge\".format(len(merged_authors)))\n",
    "\n",
    "merged_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the authors without an ID (orphan authors)\n",
    "orphan_authors = df[df['ID'].isnull()]\n",
    "print(\"   {} authors without IDs\".format(len(orphan_authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare two authors and return a value `n` indicating the probability that both authors are the same person\n",
    "def compare_authors(author, orphan):\n",
    "  n = 0\n",
    "\n",
    "  # Exact name match\n",
    "  if orphan['FULL_NAME'] in author['NM_AUTOR']: n = n + 5;\n",
    "  # Match first and last name\n",
    "  if orphan['FIRST_LAST_NAME'] in author['FIRST_LAST_NAME']: n = n + 2;\n",
    "\n",
    "  # Return if there's no chance of match\n",
    "  if n == 0: return 0\n",
    "\n",
    "  # Match abnt name\n",
    "  if orphan['NM_ABNT_AUTOR'] in author['NM_ABNT_AUTOR']: n = n + 1;\n",
    "  # Match university\n",
    "  if orphan['SG_ENTIDADE_ENSINO'] in author['SG_ENTIDADE_ENSINO']: n = n + 1;\n",
    "  # Match author type\n",
    "  if orphan['TP_AUTOR'] in author['TP_AUTOR']: n = n + 1;\n",
    "  # Match IES program\n",
    "  if orphan['CD_PROGRAMA_IES'] in author['CD_PROGRAMA_IES']: n = n + 1;\n",
    "\n",
    "  return n\n",
    "\n",
    "def update_item_count(item_count, value):\n",
    "  item_count[value] = 1 if value not in item_count else item_count[value] + 1\n",
    "\n",
    "def merge_authors(author, orphan_author):\n",
    "  merged = author.copy(deep=True)\n",
    "  for column in author.index.to_list():\n",
    "    if column not in merge_schema or column == 'FULL_NAME': continue\n",
    "    author_value = author[column]\n",
    "    orphan_value = orphan_author[column]\n",
    "    if isinstance(author_value, list):\n",
    "      author_value.append(orphan_value)\n",
    "    else:\n",
    "      update_item_count(author_value, orphan_value)\n",
    "\n",
    "  return merged\n",
    "\n",
    "# Merging orphan authors\n",
    "merge_count = 0\n",
    "append_count = 0\n",
    "\n",
    "p_authors = merged_authors\n",
    "\n",
    "def process_null_author(idx_na):\n",
    "  global merged_authors, p_authors, merge_count, append_count\n",
    "  \n",
    "  try:\n",
    "    orphan = orphan_authors.iloc[idx_na]\n",
    "    last_name = orphan['FULL_NAME'].split(' ')[-1]\n",
    "    potential_authors = merged_authors[merged_authors['FULL_NAME'].str.contains(last_name, na=False)]\n",
    "    \n",
    "    for idx_pot in range(len(potential_authors)):\n",
    "      author = potential_authors.iloc[idx_pot]\n",
    "      \n",
    "      if compare_authors(author, orphan) >= 5:\n",
    "        print(\"   üîÑ Merging authors ({})'{}' to ({})'{}'\".format(idx_na, orphan['FULL_NAME'], idx_pot, author['FULL_NAME']))\n",
    "        merged = merge_authors(author, orphan)\n",
    "        p_authors.loc[[author.name]] = pd.DataFrame(merged)\n",
    "        merge_count = merge_count + 1\n",
    "        return\n",
    "    print(\"   Appending author ({})'{}'\".format(idx_na, orphan['NM_AUTOR']))\n",
    "    orphan_df = pd.DataFrame(orphan).T.groupby(['NM_AUTOR']).agg(merge_schema)\n",
    "    p_authors = pd.concat([p_authors, orphan_df], ignore_index=True)\n",
    "    append_count = append_count + 1\n",
    "  except:\n",
    "    print(\"   Error processing author ({})'{}', '{}'  -- skipping\".format(idx_na, orphan['NM_AUTOR'], orphan['NM_ABNT_AUTOR']))\n",
    "    pass\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print('‚öôÔ∏è Merging authors without IDs (using {} cores):'.format(num_cores))\n",
    "\n",
    "# Parallel processing\n",
    "Parallel(n_jobs=num_cores, require='sharedmem')(delayed(process_null_author)(i) for i in range(len(orphan_authors)))\n",
    "\n",
    "print(\"   {} authors were merged and {} were appended to the dataset.\".format(merge_count, append_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚öôÔ∏è Exporting authors to output/processed_authors.csv...')\n",
    "p_authors.index.name = 'IDX'\n",
    "os.makedirs('output/', exist_ok=True)\n",
    "p_authors.to_csv('output/processed_authors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
