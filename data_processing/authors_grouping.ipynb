{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import os, glob, multiprocessing\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('‚öôÔ∏è Importing authors...')\n",
    "\n",
    "path = os.path.join('datasets/autores/', \"autores-*.csv\")\n",
    "data_files = glob.glob(path) \n",
    "print(*data_files, sep = \"\\n\")\n",
    "\n",
    "df = pd.concat(pd.read_csv(f, encoding='iso8859_1', delimiter=\";\") for f in data_files)\n",
    "\n",
    "# Only selects author 1% sample of the dataset\n",
    "# df = df.sample(frac=0.01, random_state=1)\n",
    "\n",
    "print(\"   {} authors in the dataset\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter fields of interest\n",
    "df = df.filter([\n",
    "  'NM_AUTOR',\n",
    "  'NM_ABNT_AUTOR',\n",
    "  'TP_AUTOR',\n",
    "  'NM_TP_CATEGORIA_DOCENTE',\n",
    "  'NM_NIVEL_DISCENTE',\n",
    "  'CD_PROGRAMA_IES',\n",
    "  'NM_PROGRAMA_IES',\n",
    "  'NM_AREA_CONHECIMENTO',\n",
    "  'SG_ENTIDADE_ENSINO',\n",
    "  'ID_PESSOA_DISCENTE',\n",
    "  'ID_PESSOA_DOCENTE',\n",
    "  'ID_PESSOA_PART_EXTERNO',\n",
    "  'ID_PESSOA_POS_DOC',\n",
    "  'ID_PESSOA_EGRESSO',\n",
    "  'ID_ADD_PRODUCAO_INTELECTUAL',\n",
    "])\n",
    "\n",
    "# Unify IDs\n",
    "def unify_ids(cols):\n",
    "    return {\n",
    "      'DOCENTE': cols['ID_PESSOA_DOCENTE'],\n",
    "      'EGRESSO': cols['ID_PESSOA_EGRESSO'],\n",
    "      'P√ìS-DOC': cols['ID_PESSOA_POS_DOC'],\n",
    "      'DISCENTE': cols['ID_PESSOA_DISCENTE'],\n",
    "      'PARTICIPANTE EXTERNO': cols['ID_PESSOA_PART_EXTERNO'],\n",
    "      '-': None,\n",
    "    }[cols['TP_AUTOR']]\n",
    "\n",
    "ids = [\n",
    "  'ID_PESSOA_DISCENTE',\n",
    "  'ID_PESSOA_DOCENTE',\n",
    "  'ID_PESSOA_PART_EXTERNO',\n",
    "  'ID_PESSOA_POS_DOC',\n",
    "  'ID_PESSOA_EGRESSO',\n",
    "]\n",
    "\n",
    "print('‚öôÔ∏è Unifying author IDs...')\n",
    "df['ID'] = df[['TP_AUTOR', *ids]].apply(unify_ids, axis=1)\n",
    "df = df.drop(columns=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚öôÔ∏è Normalizing df names...')\n",
    "df['NM_AUTOR'] = df['NM_AUTOR'].apply(utils.normalize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚öôÔ∏è Creating helper columns...')\n",
    "df['FIRST_LAST_NAME'] = df['NM_AUTOR'].apply(utils.firstAndLastName)\n",
    "df['FULL_NAME'] = df['NM_AUTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_schema = {\n",
    "  'ID': 'min',\n",
    "  'FULL_NAME': 'first',\n",
    "  'FIRST_LAST_NAME': 'first',\n",
    "  'NM_AUTOR': utils.count_to_dict,\n",
    "  'NM_ABNT_AUTOR': utils.count_to_dict,\n",
    "  'TP_AUTOR': utils.count_to_dict,\n",
    "  'NM_TP_CATEGORIA_DOCENTE': utils.count_to_dict,\n",
    "  'NM_NIVEL_DISCENTE': utils.count_to_dict,\n",
    "  'CD_PROGRAMA_IES': utils.count_to_dict,\n",
    "  'NM_PROGRAMA_IES': utils.count_to_dict,\n",
    "  'NM_AREA_CONHECIMENTO': utils.count_to_dict,\n",
    "  'SG_ENTIDADE_ENSINO': utils.count_to_dict,\n",
    "  'ID_ADD_PRODUCAO_INTELECTUAL': list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df by ID\n",
    "print('‚öôÔ∏è Merging authors by ID...')\n",
    "merged_authors = df.groupby(['ID'], sort=False, as_index=False).agg(merge_schema)\n",
    "print(\"   {} authors with ID after merge\".format(len(merged_authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get authors without an ID\n",
    "authors_without_id = df[df['ID'].isnull()]\n",
    "print(\"   {} authors without IDs\".format(len(authors_without_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group authors without ID by name\n",
    "print('‚öôÔ∏è Merging authors without ID by name...')\n",
    "authors_without_id = authors_without_id.groupby(['FULL_NAME'], sort=False, as_index=False).agg(merge_schema)\n",
    "print(\"   {} authors without IDs after merge\".format(len(authors_without_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate authors without ID with merged authors\n",
    "all_authors = pd.concat([merged_authors, authors_without_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all authors by name\n",
    "print('‚öôÔ∏è Merging all {} authors by name...'.format(len(all_authors)))\n",
    "merge_schema['ID_ADD_PRODUCAO_INTELECTUAL'] = sum\n",
    "merged_authors = all_authors.groupby(['FULL_NAME'], sort=False, as_index=False).agg(merge_schema)\n",
    "print(\"   {} authors after merge\".format(len(merged_authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export preliminary authors dataset\n",
    "# This dataset includes all the authors merged by ID and Full Name only\n",
    "# and can be generated much faster when compared to the complete dataset\n",
    "utils.export_authors_dataframe(merged_authors, 'processed_authors_preliminary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_authors.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the authors without an ID\n",
    "authors_without_id = merged_authors[merged_authors['ID'].isnull()]\n",
    "\n",
    "# Generate IDs for authors without ID\n",
    "authors_without_id['ID'] = authors_without_id.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all authors with IDs\n",
    "authors_with_id = merged_authors[merged_authors['ID'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging orphan authors\n",
    "merge_count = 0\n",
    "append_count = 0\n",
    "\n",
    "final_authors = authors_with_id\n",
    "\n",
    "def process_null_author(idx_na):\n",
    "  global merged_authors, final_authors, merge_count, append_count\n",
    "  \n",
    "  try:\n",
    "    orphan = authors_without_id.iloc[idx_na]\n",
    "    last_name = orphan['FULL_NAME'].split(' ')[-1]\n",
    "    potential_authors = final_authors[final_authors['FULL_NAME'].str.contains(last_name, na=False)]\n",
    "    \n",
    "    for idx_pot in range(len(potential_authors)):\n",
    "      author = potential_authors.iloc[idx_pot]\n",
    "      \n",
    "      if utils.compare_authors(author, orphan) >= 5:\n",
    "        print(\"   üîÑ Merging authors ({})'{}' to ({})'{}'\".format(idx_na, orphan['FULL_NAME'], idx_pot, author['FULL_NAME']))\n",
    "        merged = utils.merge_authors(author, orphan, merge_schema)\n",
    "        final_authors.loc[[author.name]] = pd.DataFrame(merged)\n",
    "        merge_count = merge_count + 1\n",
    "        return\n",
    "    print(\"   ‚ûï Appending author ({})'{}'\".format(idx_na, orphan['NM_AUTOR']))\n",
    "    final_authors = pd.concat([final_authors, orphan], ignore_index=True)\n",
    "    append_count = append_count + 1\n",
    "  except Exception as e:\n",
    "    print(\"   Error processing author ({})'{}', '{}': {}  -- skipping\".format(idx_na, orphan['NM_AUTOR'], orphan['NM_ABNT_AUTOR'], e))\n",
    "    pass\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print('‚öôÔ∏è Merging {} authors without IDs (using {} cores):'.format(len(authors_without_id), num_cores))\n",
    "\n",
    "# Parallel processing\n",
    "Parallel(n_jobs=num_cores, require='sharedmem')(delayed(process_null_author)(i) for i in range(len(authors_without_id)))\n",
    "\n",
    "print(\"   {} authors were merged and {} were appended to the dataset.\".format(merge_count, append_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export complete authors dataset\n",
    "utils.export_authors_dataframe(final_authors, 'processed_authors_complete.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
